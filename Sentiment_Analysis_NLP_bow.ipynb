{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "806aff12c6c1929f809fc1f3600fb60e0618d2fb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\devan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing all the neccessary libraries\n",
    "%matplotlib inline\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer, CountVectorizer\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_score, recall_score, f1_score\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "#from gensim.models import Word2Vec, KeyedVectors\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn import datasets, neighbors\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "from matplotlib.colors import ListedColormap\n",
    "#import scikitplot.metrics as sciplot\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "import nltk\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP -- natural language processing\n",
    "\n",
    "English\n",
    "\n",
    "Whenever u r dealing with text data that will be called as natural languag eprocessing\n",
    "\n",
    "As of now in all our projects, we hace seen numerical data(int data, float data), categorical data(object data), datetime data(date data)\n",
    "\n",
    "But now we are going to see text data(string data--- example: reviews, comments, feedbacks, tweets, etc)\n",
    "\n",
    "How is ur product and how r u satisfied wit the product:\n",
    "\n",
    "Reviews, comments, feedbacks, tweets, etc -- is our text datasets\n",
    "\n",
    "Sentiment Analysis: meaninig -- finding the sentiment of the text data --- whether the text data is positive, negative or neutral\n",
    "\n",
    "\n",
    "The benefit of sentiment analysis is that it helps businesses understand customer opinions, improve products and services, and make informed decisions based on customer feedback.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use below link to download the dataset\n",
    "##### https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9cfe62a2a72a6ded8360b64245245ae2fc231eac"
   },
   "source": [
    "#### The immediate code block below does the following things :\n",
    "\n",
    "1. Load the Amazon dataset.\n",
    "2. Classify the reviews initially based on their score rating and give them a 'Positve' or a 'Negative' tag.\n",
    "3. Remove duplicate/redundant datas.\n",
    "4. Get an idea of how much percentage data were actually duplicates.\n",
    "5. Plot a histogram which will display the distribution of the number of positive and negative reviews after de-duplication.\n",
    "\n",
    "###### NOTE : If we dont' clean the data and feed them to an ML system, it basically means we are throwing in a lot of garbage data to the ML system. If we give it garbage, it will give us garbage back. So it's utmost important to clean the data before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data=pd.read_csv(\"Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = filtered_data.sample(frac=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score ranges from 1 to 5\n",
    "\n",
    "below 3 -- negative review\n",
    "above 3 -- positive review\n",
    "equal to 3 -- neutral review\n",
    "\n",
    "What if i don't have scores in my dataset?\n",
    "Based on text data: whether the text data is positive, negative or neutral\n",
    "Key words from the text data:\n",
    "How to identify positive, negative and neutral words from the text data?\n",
    "positive words: good, excellent, nice, amazing, fantastic, love, great, satisfied, happy, wonderful -- in one dictionary\n",
    "Negative words: bad, poor, terrible, awful, hate, worst, disappointed, unsatisfied, unhappy -- in another dictionary\n",
    "\n",
    "There may be a chnance that some words may be present in both the dictionaries:\n",
    "How to deal with this: we will give more priority to negative words than positive words\n",
    "\n",
    "What is naother way to identify positive, negative and neutral words from the text data?\n",
    "We can use some pre defined libraries in python:nltk -- natural language toolkit    \n",
    "\n",
    "Input text data --- I can build any clustering algorithm(three clusters) to identify positive, negative and neutral words from the text data\n",
    "\n",
    "I am very bad satsfied with the product -- he will give rating as 4    \n",
    "\n",
    "Sarcasm -- he will give rating as 4 but the review is negative\n",
    "\n",
    "example for sarcasm: The product is good but the service is bad    -- TATA cars --- \n",
    "\n",
    "With in the tool we need to identify the positive, negative and neutral , sarcasm words from the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56845, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>288312</th>\n",
       "      <td>288313</td>\n",
       "      <td>B000ENUC3S</td>\n",
       "      <td>AN66F3Q4QNU43</td>\n",
       "      <td>Donna Speaker</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1340496000</td>\n",
       "      <td>Cherry Pie Larabar</td>\n",
       "      <td>I love the Cherry Pie Lara bar.  Best and tast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431726</th>\n",
       "      <td>431727</td>\n",
       "      <td>B002TMV3CG</td>\n",
       "      <td>A3G007LQX6KGOD</td>\n",
       "      <td>SevereWX</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1287878400</td>\n",
       "      <td>Melitta Coffee</td>\n",
       "      <td>Melitta Cafe COllection Blanc et Noir coffee h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110311</th>\n",
       "      <td>110312</td>\n",
       "      <td>B004867T24</td>\n",
       "      <td>A11LNY2OLQSUSV</td>\n",
       "      <td>M. Castillo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1331769600</td>\n",
       "      <td>great treat</td>\n",
       "      <td>my girls absolutely loved this tuna. they were...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91855</th>\n",
       "      <td>91856</td>\n",
       "      <td>B004U7KPY0</td>\n",
       "      <td>A1QCYVHWO5934U</td>\n",
       "      <td>PistolaMia \"PistolaMia\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1332806400</td>\n",
       "      <td>Daily Calming</td>\n",
       "      <td>The vendor is fast and dependable. The tea is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338855</th>\n",
       "      <td>338856</td>\n",
       "      <td>B000FD78R0</td>\n",
       "      <td>A30U2QQN2FFHE9</td>\n",
       "      <td>J. Amicucci</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1271376000</td>\n",
       "      <td>Best Canned Artichokes Out There!</td>\n",
       "      <td>UPDATE - 8/9/2010&lt;br /&gt;A lot can happen in jus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId              ProfileName  \\\n",
       "288312  288313  B000ENUC3S   AN66F3Q4QNU43            Donna Speaker   \n",
       "431726  431727  B002TMV3CG  A3G007LQX6KGOD                 SevereWX   \n",
       "110311  110312  B004867T24  A11LNY2OLQSUSV              M. Castillo   \n",
       "91855    91856  B004U7KPY0  A1QCYVHWO5934U  PistolaMia \"PistolaMia\"   \n",
       "338855  338856  B000FD78R0  A30U2QQN2FFHE9              J. Amicucci   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "288312                     0                       0      5  1340496000   \n",
       "431726                     0                       0      5  1287878400   \n",
       "110311                     0                       0      5  1331769600   \n",
       "91855                      0                       0      5  1332806400   \n",
       "338855                     2                       3      5  1271376000   \n",
       "\n",
       "                                  Summary  \\\n",
       "288312                 Cherry Pie Larabar   \n",
       "431726                     Melitta Coffee   \n",
       "110311                        great treat   \n",
       "91855                       Daily Calming   \n",
       "338855  Best Canned Artichokes Out There!   \n",
       "\n",
       "                                                     Text  \n",
       "288312  I love the Cherry Pie Lara bar.  Best and tast...  \n",
       "431726  Melitta Cafe COllection Blanc et Noir coffee h...  \n",
       "110311  my girls absolutely loved this tuna. they were...  \n",
       "91855   The vendor is fast and dependable. The tea is ...  \n",
       "338855  UPDATE - 8/9/2010<br />A lot can happen in jus...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Give reviews with Score > 3 a 'Positive' tag, and reviews with a score < 3 a 'Negative' tag.\n",
    "filtered_data['SentimentPolarity'] = filtered_data['Score'].apply(lambda x : 'Positive' if x > 3 else 'Negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>SentimentPolarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>288312</th>\n",
       "      <td>288313</td>\n",
       "      <td>B000ENUC3S</td>\n",
       "      <td>AN66F3Q4QNU43</td>\n",
       "      <td>Donna Speaker</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1340496000</td>\n",
       "      <td>Cherry Pie Larabar</td>\n",
       "      <td>I love the Cherry Pie Lara bar.  Best and tast...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431726</th>\n",
       "      <td>431727</td>\n",
       "      <td>B002TMV3CG</td>\n",
       "      <td>A3G007LQX6KGOD</td>\n",
       "      <td>SevereWX</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1287878400</td>\n",
       "      <td>Melitta Coffee</td>\n",
       "      <td>Melitta Cafe COllection Blanc et Noir coffee h...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId    ProfileName  \\\n",
       "288312  288313  B000ENUC3S   AN66F3Q4QNU43  Donna Speaker   \n",
       "431726  431727  B002TMV3CG  A3G007LQX6KGOD       SevereWX   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "288312                     0                       0      5  1340496000   \n",
       "431726                     0                       0      5  1287878400   \n",
       "\n",
       "                   Summary                                               Text  \\\n",
       "288312  Cherry Pie Larabar  I love the Cherry Pie Lara bar.  Best and tast...   \n",
       "431726      Melitta Coffee  Melitta Cafe COllection Blanc et Noir coffee h...   \n",
       "\n",
       "       SentimentPolarity  \n",
       "288312          Positive  \n",
       "431726          Positive  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentPolarity\n",
       "Positive    44391\n",
       "Negative    12454\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data['SentimentPolarity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#score greater than 3 as postive  and equal to 3 as neutral and less than 3 as negative\n",
    "#filtered_data['SentimentPolarity'] = filtered_data['Score'].apply(lambda x : 'Positive' if x > 3 else (if x < 3 else 'Neutral'))\n",
    "#score greater than 3 as postive  and equal to 3 as neutral and less than 3 as negative and give more priority to negative words\n",
    "#filtered_data['SentimentPolarity'] = filtered_data['Score'].apply(lambda x : 'Positive' if x > 3 else ('Negative' if x < 3 else 'Neutral'))\n",
    "filtered_data['Class_Labels'] = filtered_data['SentimentPolarity'].apply(lambda x : 1 if x == 'Positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>SentimentPolarity</th>\n",
       "      <th>Class_Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>288312</th>\n",
       "      <td>288313</td>\n",
       "      <td>B000ENUC3S</td>\n",
       "      <td>AN66F3Q4QNU43</td>\n",
       "      <td>Donna Speaker</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1340496000</td>\n",
       "      <td>Cherry Pie Larabar</td>\n",
       "      <td>I love the Cherry Pie Lara bar.  Best and tast...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431726</th>\n",
       "      <td>431727</td>\n",
       "      <td>B002TMV3CG</td>\n",
       "      <td>A3G007LQX6KGOD</td>\n",
       "      <td>SevereWX</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1287878400</td>\n",
       "      <td>Melitta Coffee</td>\n",
       "      <td>Melitta Cafe COllection Blanc et Noir coffee h...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId    ProfileName  \\\n",
       "288312  288313  B000ENUC3S   AN66F3Q4QNU43  Donna Speaker   \n",
       "431726  431727  B002TMV3CG  A3G007LQX6KGOD       SevereWX   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "288312                     0                       0      5  1340496000   \n",
       "431726                     0                       0      5  1287878400   \n",
       "\n",
       "                   Summary                                               Text  \\\n",
       "288312  Cherry Pie Larabar  I love the Cherry Pie Lara bar.  Best and tast...   \n",
       "431726      Melitta Coffee  Melitta Cafe COllection Blanc et Noir coffee h...   \n",
       "\n",
       "       SentimentPolarity  Class_Labels  \n",
       "288312          Positive             1  \n",
       "431726          Positive             1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Create dictionaries of positive and negative words from the 'Text' column\\nfrom collections import defaultdict\\nimport re\\n\\nrevie1: the product is Great    --- positive\\nreview2: the product is not Great   --- negative label\\n\\nAlgorithm to create the labels: clustering algorithms -- we don't need to create any labels\\n\\npositive_words_dict = defaultdict(int)\\nnegative_words_dict = defaultdict(int)\\n\\nfor idx, row in filtered_data.iterrows():\\n    # Clean and tokenize the review text\\n    words = re.findall(r'\\x08\\\\w+\\x08', str(row['Text']).lower())\\n    if row['SentimentPolarity'] == 'Positive':\\n        for word in words:\\n            positive_words_dict[word] += 1\\n    elif row['SentimentPolarity'] == 'Negative':\\n        for word in words:\\n            negative_words_dict[word] += 1\\n\\n# Convert defaultdict to regular dict for display\\npositive_words_dict = dict(positive_words_dict)\\nnegative_words_dict = dict(negative_words_dict)\\n\\nprint('Sample positive words:', list(positive_words_dict.keys())[:20])\\nprint('Sample negative words:', list(negative_words_dict.keys())[:20])\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Create dictionaries of positive and negative words from the 'Text' column\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "revie1: the product is Great    --- positive\n",
    "review2: the product is not Great   --- negative label\n",
    "\n",
    "Algorithm to create the labels: clustering algorithms -- we don't need to create any labels\n",
    "\n",
    "positive_words_dict = defaultdict(int)\n",
    "negative_words_dict = defaultdict(int)\n",
    "\n",
    "for idx, row in filtered_data.iterrows():\n",
    "    # Clean and tokenize the review text\n",
    "    words = re.findall(r'\\b\\w+\\b', str(row['Text']).lower())\n",
    "    if row['SentimentPolarity'] == 'Positive':\n",
    "        for word in words:\n",
    "            positive_words_dict[word] += 1\n",
    "    elif row['SentimentPolarity'] == 'Negative':\n",
    "        for word in words:\n",
    "            negative_words_dict[word] += 1\n",
    "\n",
    "# Convert defaultdict to regular dict for display\n",
    "positive_words_dict = dict(positive_words_dict)\n",
    "negative_words_dict = dict(negative_words_dict)\n",
    "\n",
    "print('Sample positive words:', list(positive_words_dict.keys())[:20])\n",
    "print('Sample negative words:', list(negative_words_dict.keys())[:20])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56845, 12)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of positive and negative reviews before the removal of duplicate data.\n",
      "SentimentPolarity\n",
      "Positive    44391\n",
      "Negative    12454\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of positive and negative reviews before the removal of duplicate data.\")\n",
    "print(filtered_data[\"SentimentPolarity\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing duplicate entries based on past knowledge.\n",
    "filtered_duplicates=filtered_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of positive and negative reviews after the removal of duplicate data.\n",
      "SentimentPolarity\n",
      "Positive    40741\n",
      "Negative    11450\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of positive and negative reviews after the removal of duplicate data.\")\n",
    "print(filtered_data[\"SentimentPolarity\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the entries where HelpfulnessNumerator > HelpfulnessDenominator.\n",
    "final_data=filtered_data[filtered_data.HelpfulnessNumerator <= filtered_data.HelpfulnessDenominator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentPolarity\n",
       "Positive    40741\n",
       "Negative    11450\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data[\"SentimentPolarity\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0c1ceff8d19cc6fcab4ef1deecff7fd5eb765083"
   },
   "source": [
    "#### In this code block :\n",
    "\n",
    "1. I am creating a copy of the final_data dataset called 'sampled_dataset' by dropping the unwanted columns that we don't need for this problem.\n",
    "2. Sorting the data according to time, such that the oldest reviews are displayed at the top and the latest reviews are displayed at the bottom.\n",
    "3. Displaying information about the number of postive and negative reviews in the sampled dataset, using a Histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the sampled dataset after dropping unwanted columns :  (52191, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Text</th>\n",
       "      <th>SentimentPolarity</th>\n",
       "      <th>Class_Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>288312</th>\n",
       "      <td>1340496000</td>\n",
       "      <td>I love the Cherry Pie Lara bar.  Best and tast...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431726</th>\n",
       "      <td>1287878400</td>\n",
       "      <td>Melitta Cafe COllection Blanc et Noir coffee h...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110311</th>\n",
       "      <td>1331769600</td>\n",
       "      <td>my girls absolutely loved this tuna. they were...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91855</th>\n",
       "      <td>1332806400</td>\n",
       "      <td>The vendor is fast and dependable. The tea is ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338855</th>\n",
       "      <td>1271376000</td>\n",
       "      <td>UPDATE - 8/9/2010&lt;br /&gt;A lot can happen in jus...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Time                                               Text  \\\n",
       "288312  1340496000  I love the Cherry Pie Lara bar.  Best and tast...   \n",
       "431726  1287878400  Melitta Cafe COllection Blanc et Noir coffee h...   \n",
       "110311  1331769600  my girls absolutely loved this tuna. they were...   \n",
       "91855   1332806400  The vendor is fast and dependable. The tea is ...   \n",
       "338855  1271376000  UPDATE - 8/9/2010<br />A lot can happen in jus...   \n",
       "\n",
       "       SentimentPolarity  Class_Labels  \n",
       "288312          Positive             1  \n",
       "431726          Positive             1  \n",
       "110311          Positive             1  \n",
       "91855           Positive             1  \n",
       "338855          Positive             1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping unwanted columns for now.\n",
    "sampled_dataset=final_data.drop(labels=['Id','ProductId', 'UserId', 'Score', 'ProfileName','HelpfulnessNumerator', 'HelpfulnessDenominator','Summary'], axis=1)\n",
    "print(\"The shape of the sampled dataset after dropping unwanted columns : \", sampled_dataset.shape)\n",
    "sampled_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting data according to Time in ascending order => Time Based Splitting Step 1.\n",
    "sampled_dataset=sampled_dataset.sort_values('Time', axis=0, ascending=False, inplace=False, kind='quicksort', na_position='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_dataset = sampled_dataset.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Time</th>\n",
       "      <th>Text</th>\n",
       "      <th>SentimentPolarity</th>\n",
       "      <th>Class_Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>429990</td>\n",
       "      <td>1351209600</td>\n",
       "      <td>Great flavor.....lotsa &amp;#34;heat&amp;#34;....I use...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>516146</td>\n",
       "      <td>1351209600</td>\n",
       "      <td>I was skeptical about ordering what with the t...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index        Time                                               Text  \\\n",
       "0  429990  1351209600  Great flavor.....lotsa &#34;heat&#34;....I use...   \n",
       "1  516146  1351209600  I was skeptical about ordering what with the t...   \n",
       "\n",
       "  SentimentPolarity  Class_Labels  \n",
       "0          Positive             1  \n",
       "1          Negative             0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_dataset=sampled_dataset.drop(labels=['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Distribution Of Positive and Negative reviews after De-Duplication.'}, xlabel='SentimentPolarity'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display distribution of Postive and Negative reviews in a bar graph\n",
    "sampled_dataset[\"SentimentPolarity\"].value_counts().plot(kind='bar',color=['green','red'],title='Distribution Of Positive and Negative reviews after De-Duplication.',figsize=(5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b5a929f556bfc96f3a3dacf9ad0fb5a32d20ea72"
   },
   "source": [
    "#### In this code block :\n",
    "\n",
    "1. We define two functions which will remove the HTML tags and punctuations from each review.\n",
    "2. At the end of this code block, each review will contain texts which will only contain alphabetical strings. \n",
    "3. We will apply techniques such as stemming and stopwords removal.\n",
    "3. We will create two columns in the sampled dataset - 'CleanedText' and 'RemovedHTML'.\n",
    "4. 'CleanedText' column will basically contain the data corpus after stemming the each reviews and removing stopwords from each review. We will use this for our Bag of Word model.\n",
    "5. 'RemovedHTML' column will contain the data corpus from which only the HTML tags and punctuations are removed. We will use this column for our TF-IDF model, Average Word2Vec model and TF-IDF weighted average Word2Vec model.\n",
    "6. Store the final table in a dataset called 'sampled_dataset' for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "review = \"i am satisfied with the product , and the service is good... @  ! 7 % $ and the delivery is on time <br /> <br /> overall i am happy with the product.product\"\n",
    "\n",
    "\n",
    "'''Data Cleaning Stage. Clean each review from the sampled Amazon Dataset.'''\n",
    "#Data Cleaning Stage. Clean each review from the sampled Amazon Dataset\n",
    "\n",
    "#Function to clean html tags from a sentence\n",
    "def removeHtml(sentence): \n",
    "    pattern = re.compile('<.*?>')\n",
    "    cleaned_text = re.sub(pattern,' ',sentence)\n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review after removing html tags :  i am satisfied with the product , and the service is good... @  ! 7 % $ and the delivery is on time     overall i am happy with the product.product\n"
     ]
    }
   ],
   "source": [
    "cleaned_review=removeHtml(review)\n",
    "print(\"The review after removing html tags : \",cleaned_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to keep only words containing letters A-Z and a-z. This will remove all punctuations, special characters etc.\n",
    "def removePunctuations(sentence):\n",
    "    cleaned_text  = re.sub('[^a-zA-Z]',' ',sentence)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review after removing  Punctuations :  i am satisfied with the product   and the service is good               and the delivery is on time     overall i am happy with the product product\n"
     ]
    }
   ],
   "source": [
    "cleaned_review_only_text = removePunctuations(cleaned_review)\n",
    "print(\"The review after removing  Punctuations : \",cleaned_review_only_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ineed to strip the text data and convert it into lower case\n",
    "#Function to convert the entire sentence to lower case and strip the extra spaces.  \n",
    "def stripLower(sentence):\n",
    "    cleaned_text = sentence.lower().strip()\n",
    "    cleaned_text = re.sub(' +', ' ', cleaned_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review after converting to lower case and stripping extra spaces :  i am satisfied with the product and the service is good and the delivery is on time overall i am happy with the product product\n"
     ]
    }
   ],
   "source": [
    "final_cleaned_review = stripLower(cleaned_review_only_text)\n",
    "print(\"The review after converting to lower case and stripping extra spaces : \",final_cleaned_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i am satisfied with the product and the service is good and the delivery is on time overall i am happy with the product product'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_cleaned_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review after taking only distinct words :  i am satisfied with the product and service is good delivery on time overall happy\n"
     ]
    }
   ],
   "source": [
    "def take_only_distinct_words(sentence):\n",
    "    word_tokens = sentence.split()\n",
    "    #print(\"The word tokens are : \", word_tokens)\n",
    "    seen = set()\n",
    "    cleaned_text = []\n",
    "    for word in word_tokens:\n",
    "        if word not in seen:\n",
    "            cleaned_text.append(word)\n",
    "            seen.add(word)\n",
    "    #print(\"The distinct words are : \", cleaned_text)\n",
    "    cleaned_text = ' '.join(cleaned_text)\n",
    "    return cleaned_text\n",
    "\n",
    "cleaned_review_distinct_words = take_only_distinct_words(final_cleaned_review)\n",
    "print(\"The review after taking only distinct words : \", cleaned_review_distinct_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\devan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk   #spacy\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " \"he's\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " \"i've\",\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " \"we've\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\devan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# my next step is to remove stop words from the text data\n",
    "#Function to remove stop words from a sentence  \n",
    "nltk.download('stopwords')\n",
    "def removeStopWords(sentence):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # need to take all negative words from the stop words in list after that we will remove those words from the stop words\n",
    "    #print(\"The stop words are : \", stop_words)\n",
    "    negative_words = [\"not\", \"no\", \"nor\", \"never\", \"don't\", \"didn't\", \"doesn't\", \"isn't\", \"wasn't\", \"shouldn't\", \"wouldn't\", \"couldn't\", \"won't\", \"haven't\", \"hasn't\", \"hadn't\", \"mightn't\", \"mustn't\", \"shan't\"]\n",
    "    #print(\"The negative words are : \", negative_words)\n",
    "    stop_words = stop_words - set(negative_words)\n",
    "    word_tokens = sentence.split()\n",
    "    cleaned_text = [word for word in word_tokens if not word in stop_words]\n",
    "    cleaned_text = ' '.join(cleaned_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_after_stopwords = removeStopWords(cleaned_review_distinct_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rev_after_stopwords\n",
    "\n",
    "#satisfy, satisfied, satisfied, satisfaction, satisfactory, satisfyingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example_review_for_stemming = \"i am satisfied with the product and the service is good and satisfy overall the satisfaction is good\"\n",
    "rev_test = \"satisfy  satisfied  satisfied satisfaction satisfactory satisfyingly\"\n",
    "# next step is to use stemming or  lemmatisation on the text data:\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "def stemming(sentence):\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    word_tokens = sentence.split()\n",
    "    cleaned_text = [porter_stemmer.stem(word) for word in word_tokens]\n",
    "    cleaned_text = ' '.join(cleaned_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review after stemming :  satisfi satisfi satisfi satisfact satisfactori satisfyingli\n"
     ]
    }
   ],
   "source": [
    "review_after_stemming = stemming(rev_test)\n",
    "print(\"The review after stemming : \",review_after_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to use the stemming technique with snowball stemmer\n",
    "def stemming_with_snowball(sentence):\n",
    "    from nltk.stem.snowball import SnowballStemmer\n",
    "    snowball_stemmer = SnowballStemmer(language='english')\n",
    "    word_tokens = sentence.split()\n",
    "    cleaned_text = [snowball_stemmer.stem(word) for word in word_tokens]\n",
    "    cleaned_text = ' '.join(cleaned_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review after snowball stemmer :  satisfi satisfi satisfi satisfact satisfactori satisfi\n"
     ]
    }
   ],
   "source": [
    "review_after_snowball_stemming = stemming_with_snowball(rev_test)\n",
    "print(\"The review after snowball stemmer : \",review_after_snowball_stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming Vs Lemmatisation Explanation:\n",
    "Stemming and lemmatization are both techniques used in natural language processing (NLP) to reduce words to their base or root form, but they do so in different ways and with different levels of accuracy.\n",
    "Stemming:\n",
    "Stemming is a crude heuristic process that chops off the ends of words in the hope of achieving the correct base form of the word. It often involves removing common prefixes or suffixes. Stemming algorithms, such as the Porter Stemmer or Snowball Stemmer, use simple rules to perform this task.\n",
    "Lemmatisation:\n",
    "Lemmatisation, on the other hand, is a more sophisticated process that considers the context and the morphological analysis of words. It involves using a vocabulary and morphological analysis of words to return the base or dictionary form of a word, known as the lemma. Lemmatisation takes into account the part of speech and the meaning of the word, which often results in more accurate base forms. For example, the lemma of \"better\" is \"good,\" and the lemma of \"running\" is \"run.\"\n",
    "Lemmatisation typically requires more computational resources and is slower than stemming due to its complexity and reliance on linguistic knowledge.\n",
    "\n",
    "\n",
    "Stemming is faster and more efficient, while lemmatization is more accurate and context-aware. The choice between the two depends on the specific requirements of the NLP task at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review after lemmatization :  satisfy satisfied satisfied satisfaction satisfactory satisfyingly\n"
     ]
    }
   ],
   "source": [
    "def lemmatization(sentence):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_tokens = sentence.split()\n",
    "    cleaned_text = [lemmatizer.lemmatize(word) for word in word_tokens]\n",
    "    cleaned_text = ' '.join(cleaned_text)\n",
    "    return cleaned_text\n",
    "\n",
    "review_after_lemmatization = lemmatization(rev_test)\n",
    "print(\"The review after lemmatization : \",review_after_lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Text</th>\n",
       "      <th>SentimentPolarity</th>\n",
       "      <th>Class_Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1351209600</td>\n",
       "      <td>Great flavor.....lotsa &amp;#34;heat&amp;#34;....I use...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1351209600</td>\n",
       "      <td>I was skeptical about ordering what with the t...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time                                               Text  \\\n",
       "0  1351209600  Great flavor.....lotsa &#34;heat&#34;....I use...   \n",
       "1  1351209600  I was skeptical about ordering what with the t...   \n",
       "\n",
       "  SentimentPolarity  Class_Labels  \n",
       "0          Positive             1  \n",
       "1          Negative             0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(sentence):\n",
    "    sentence = removeHtml(sentence)\n",
    "    sentence = removePunctuations(sentence)\n",
    "    sentence = stripLower(sentence)\n",
    "    sentence = take_only_distinct_words(sentence)\n",
    "    sentence = removeStopWords(sentence)\n",
    "    sentence = stemming(sentence)\n",
    "    return sentence\n",
    "# we will call this function for each and every review in our dataset\n",
    "sampled_dataset['Cleaned_Text'] = sampled_dataset['Text'].apply(data_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Text</th>\n",
       "      <th>SentimentPolarity</th>\n",
       "      <th>Class_Labels</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1351209600</td>\n",
       "      <td>Great flavor.....lotsa &amp;#34;heat&amp;#34;....I use...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>great flavor lotsa heat use cayenn almost ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1351209600</td>\n",
       "      <td>I was skeptical about ordering what with the t...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>skeptic order troubl cup explod find howev ful...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time                                               Text  \\\n",
       "0  1351209600  Great flavor.....lotsa &#34;heat&#34;....I use...   \n",
       "1  1351209600  I was skeptical about ordering what with the t...   \n",
       "\n",
       "  SentimentPolarity  Class_Labels  \\\n",
       "0          Positive             1   \n",
       "1          Negative             0   \n",
       "\n",
       "                                        Cleaned_Text  \n",
       "0  great flavor lotsa heat use cayenn almost ever...  \n",
       "1  skeptic order troubl cup explod find howev ful...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_dataset = sampled_dataset[['Time','Cleaned_Text','Class_Labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52191, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Class_Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1351209600</td>\n",
       "      <td>great flavor lotsa heat use cayenn almost ever...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1351209600</td>\n",
       "      <td>skeptic order troubl cup explod find howev ful...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1351209600</td>\n",
       "      <td>love faucet husband instal one old hous curren...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1351209600</td>\n",
       "      <td>dog come outsid train look cupboard wait treat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1351209600</td>\n",
       "      <td>everi month give three dog two aussi golden fl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time                                       Cleaned_Text  Class_Labels\n",
       "0  1351209600  great flavor lotsa heat use cayenn almost ever...             1\n",
       "1  1351209600  skeptic order troubl cup explod find howev ful...             0\n",
       "2  1351209600  love faucet husband instal one old hous curren...             1\n",
       "3  1351209600  dog come outsid train look cupboard wait treat...             1\n",
       "4  1351209600  everi month give three dog two aussi golden fl...             1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sampled_dataset.shape)\n",
    "sampled_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class_Labels\n",
       "1    40741\n",
       "0    11450\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_dataset['Class_Labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data set into train and test sets. The test set should be unseen. Time Based Splitting Step 2.\n",
    "#The top old 80% data will get into the train set. The latest 20% data will get into the test set.\n",
    "def splitting_data(data):\n",
    "    X = data['Cleaned_Text']\n",
    "    y = data['Class_Labels']\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = splitting_data(sampled_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        great flavor lotsa heat use cayenn almost ever...\n",
       "1        skeptic order troubl cup explod find howev ful...\n",
       "2        love faucet husband instal one old hous curren...\n",
       "3        dog come outsid train look cupboard wait treat...\n",
       "4        everi month give three dog two aussi golden fl...\n",
       "                               ...                        \n",
       "52186    beetlejuic not movi watch time one funiest mov...\n",
       "52187    set small new england town tim burton masterpi...\n",
       "52188    michael keaton alreadi way major star play gho...\n",
       "52189    beetlejuic awe inspir wonder amus comed romp e...\n",
       "52190    twist rumplestiskin captur film star michael k...\n",
       "Name: Cleaned_Text, Length: 52191, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        0\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "52186    1\n",
       "52187    1\n",
       "52188    1\n",
       "52189    1\n",
       "52190    1\n",
       "Name: Class_Labels, Length: 52191, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 days data\n",
    "\n",
    "8 days of data i can take as train data\n",
    "2 days of data i can take as test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The split value is :  41752\n"
     ]
    }
   ],
   "source": [
    "# taking first 80% data as train data and last 20% data as test data\n",
    "split = math.floor(0.8*len(X))\n",
    "print(\"The split value is : \", split)\n",
    "X_train = X[0:split,] ; y_train = y[0:split,]\n",
    "\n",
    "X_test = X[split:,] ; y_test = y[split:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41752,)\n",
      "(10439,)\n",
      "(41752,)\n",
      "(10439,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        great flavor lotsa heat use cayenn almost ever...\n",
       "1        skeptic order troubl cup explod find howev ful...\n",
       "2        love faucet husband instal one old hous curren...\n",
       "3        dog come outsid train look cupboard wait treat...\n",
       "4        everi month give three dog two aussi golden fl...\n",
       "                               ...                        \n",
       "41747    big quinoa fan decid give kaniwa tri similar m...\n",
       "41748    good earth restaur tea addict continu onlin pu...\n",
       "41749    avid tea drinker drink lot green everi day gre...\n",
       "41750    one smooth rick dark chocol treat gevalia truf...\n",
       "41751    pro gevalia say dark chocol mean con sinc oz b...\n",
       "Name: Cleaned_Text, Length: 41752, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41752               order liter ate day pack addict delici\n",
       "41753    nice light simpl yet flavor dress receiv compl...\n",
       "41754    vegeta must almost everyth cook ridicul though...\n",
       "41755    tea great help concentr also tast well especi ...\n",
       "41756    tri sever frozen commerci prepar gluten free p...\n",
       "                               ...                        \n",
       "52186    beetlejuic not movi watch time one funiest mov...\n",
       "52187    set small new england town tim burton masterpi...\n",
       "52188    michael keaton alreadi way major star play gho...\n",
       "52189    beetlejuic awe inspir wonder amus comed romp e...\n",
       "52190    twist rumplestiskin captur film star michael k...\n",
       "Name: Cleaned_Text, Length: 10439, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        0\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "41747    1\n",
       "41748    1\n",
       "41749    1\n",
       "41750    1\n",
       "41751    1\n",
       "Name: Class_Labels, Length: 41752, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41752    1\n",
       "41753    1\n",
       "41754    1\n",
       "41755    1\n",
       "41756    1\n",
       "        ..\n",
       "52186    1\n",
       "52187    1\n",
       "52188    1\n",
       "52189    1\n",
       "52190    1\n",
       "Name: Class_Labels, Length: 10439, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalisation vs Standaridation\n",
    "Label Encoder vs One Hot Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can I use Label Encoder to convert the text data into numerical data?\n",
    "0\n",
    "1\n",
    "2\n",
    "3\n",
    "44\n",
    "5\n",
    "6\n",
    "7\n",
    "78\n",
    "\n",
    "9\n",
    "9\n",
    "9\n",
    "\n",
    "1,00,000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to calculate the total uniwue words in the text data of X_train data\n",
    "def total_unique_words(corpus):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    unique_words = vectorizer.get_feature_names_out()\n",
    "    return unique_words, len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words: 25399\n",
      "Sample unique words: ['aa' 'aaa' 'aaaa' 'aaaaa' 'aaaaaaaaaaaaaaaaaaaargh' 'aaaaaah' 'aaaaallll'\n",
      " 'aaaahhhhhh' 'aaah' 'aabsolut' 'aacut' 'aafco' 'aah' 'aakaufman'\n",
      " 'aalmost' 'aamazon' 'aap' 'aargh' 'aaround' 'aarti']\n"
     ]
    }
   ],
   "source": [
    "# Calculate total unique words in X_train\n",
    "unique_words, num_unique_words = total_unique_words(X_train)\n",
    "print(\"Total unique words:\", num_unique_words)\n",
    "print(\"Sample unique words:\", unique_words[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we need to convert text data into numerical data\n",
    "# we will use bag of words or tfidf vectorizer to convert text data into numerical data\n",
    "# bag of words VS TF-IDF\n",
    "# we will use tfidf vectorizer to convert text data into numerical data\n",
    "\n",
    "BOW and TF-IDF Explanation:\n",
    "Bag of Words (BoW) \n",
    "and Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "\n",
    "With example by taking few sentences as below:\n",
    "sentence1 = \"I love programming in Python\"\n",
    "sentence2 = \"Python is a great programming language\"\n",
    "sentence3 = \"I enjoy solving problems with Python\"\n",
    "\n",
    "BOW Formulation:\n",
    "1. Create a vocabulary of unique words from all sentences.\n",
    "vocabulary = [\"I\", \"love\", \"programming\", \"in\", \"Python\", \"is\", \"a\", \"great\", \"language\", \"enjoy\", \"solving\", \"problems\", \"with\"]\n",
    "len(vocabulary) = 13\n",
    "2. Represent each sentence as a vector based on the frequency of words in the vocabulary.\n",
    "maintain the count of each word in one dictionary to see the count of each and every words\n",
    "words_count = {\n",
    "    \"I\": 2,\n",
    "    \"love\": 1,\n",
    "    \"programming\": 2,\n",
    "    \"in\": 1,\n",
    "    \"Python\": 3,\n",
    "    \"is\": 1,\n",
    "    \"a\": 1,\n",
    "    \"great\": 1,\n",
    "    \"language\": 1,\n",
    "    \"enjoy\": 1,\n",
    "    \"solving\": 1,\n",
    "    \"problems\": 1,\n",
    "    \"with\": 1\n",
    "}\n",
    "# Example BOW vectors\n",
    "sentence1 = \"I love programming in Python\"\n",
    "sentence1_vector = [2, 1, 2, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "sentence2 = \"Python is a great programming language\"\n",
    "sentence2_vector = [0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0]\n",
    "sentence3 = \"I enjoy solving problems with Python\"\n",
    "sentence3_vector = [1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1]\n",
    "\n",
    "1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0    1\n",
    "0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0    1\n",
    "\n",
    "TF-IDF Formulation:\n",
    "1. Calculate Term Frequency (TF) for each word in a sentence.  \n",
    "TF(word) = (Number of times word appears in a sentence) / (Total number of words in the sentence)\n",
    "TF(\"Python\", sentence1) = 1/5 = 0.2\n",
    "TF(\"programming\", sentence1) = 1/5 = 0.2\n",
    "TF(\"I\", sentence1) = 1/5 = 0.2\n",
    "TF(\"love\", sentence1) = 1/5 = 0.2\n",
    "TF(\"in\", sentence1) = 1/5 = 0.2\n",
    "TF(\"is\", sentence2) = 1/7 = 0.14\n",
    "TF(\"great\", sentence2) = 1/7 = 0.14 \n",
    "TF(\"language\", sentence2) = 1/7 = 0.14\n",
    "TF(\"a\", sentence2) = 1/7 = 0.14\n",
    "TF(\"enjoy\", sentence3) = 1/6 = 0.17\n",
    "TF(\"solving\", sentence3) = 1/6 = 0.17\n",
    "TF(\"problems\", sentence3) = 1/6 = 0.17\n",
    "TF(\"with\", sentence3) = 1/6 = 0.17\n",
    "TF(\"I\", sentence3) = 1/6 = 0.17 \n",
    "TF(\"Python\", sentence3) = 1/6 = 0.17\n",
    "IDF ( Inverse Document Frequency)\n",
    "IDF(word) = log_e(Total number of sentences / Number of sentences with the word in it)\n",
    "IDF(\"Python\") = log_e(3/3) = 0\n",
    "IDF(\"programming\") = log_e(3/2) = 0.405\n",
    "IDF(\"I\") = log_e(3/2) = 0.405\n",
    "IDF(\"love\") = log_e(3/1) = 1.098\n",
    "IDF(\"in\") = log_e(3/1) = 1.098\n",
    "IDF(\"is\") = log_e(3/1) = 1.098\n",
    "IDF(\"great\") = log_e(3/1) = 1.098\n",
    "IDF(\"language\") = log_e(3/1) = 1.098\n",
    "IDF(\"a\") = log_e(3/1) = 1.098\n",
    "IDF(\"enjoy\") = log_e(3/1) = 1.098\n",
    "IDF(\"solving\") = log_e(3/1) = 1.098\n",
    "IDF(\"problems\") = log_e(3/1) = 1.098\n",
    "IDF(\"with\") = log_e(3/1) = 1.098\n",
    "TF-IDF(word, sentence) = TF(word, sentence) * IDF(word)\n",
    "sentence1 = \"I love programming in Python\"\n",
    "TF-IDF(\"Python\", sentence1) = 0.2 * 0 = 0\n",
    "TF-IDF(\"programming\", sentence1) = 0.2 * 0.405 = 0.081\n",
    "TF-IDF(\"I\", sentence1) = 0.2 * 0.405 = 0.081\n",
    "TF-IDF(\"love\", sentence1) = 0.2 * 1.098 = 0.22\n",
    "TF-IDF(\"in\", sentence1) = 0.2 * 1.098 = 0.22\n",
    "sentence1_vector_tf-idf = [0.081, 0.22, 0.081, 0.22, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "sentence1_vector_BOW =    [2, 1, 2, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "sentence2 = \"Python is a great programming language\"\n",
    "TF-IDF(\"Python\", sentence2) = 0.14 * 0 = 0\n",
    "TF-IDF(\"is\", sentence2) = 0.14 * 1.098 = 0.154\n",
    "TF-IDF(\"a\", sentence2) = 0.14 * 1.098 = 0.154\n",
    "TF-IDF(\"great\", sentence2) = 0.14 * 1.098 = 0.154\n",
    "TF-IDF(\"programming\", sentence2) = 0.14 * 0.405 = 0.057\n",
    "TF-IDF(\"language\", sentence2) = 0.14 * 1.098 = 0.154\n",
    "sentence2_vector_tf-idf = [0, 0, 0.057, 0, 0, 0.154, 0.154, 0.154, 0.154, 0, 0, 0, 0]\n",
    "sentence2_vector_BOW =    [0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0]\n",
    "sentence3 = \"I enjoy solving problems with Python\"\n",
    "TF-IDF(\"I\", sentence3) = 0.17 * 0.405 = 0.069\n",
    "TF-IDF(\"enjoy\", sentence3) = 0.17 * 1.098 = 0.187\n",
    "TF-IDF(\"solving\", sentence3) = 0.17 * 1.098 = 0.187\n",
    "TF-IDF(\"problems\", sentence3) = 0.17 * 1.098 = 0.187\n",
    "TF-IDF(\"with\", sentence3) = 0.17 * 1.098 = 0.187\n",
    "TF-IDF(\"Python\", sentence3) = 0.17 * 0 = 0\n",
    "sentence3_vector_tf-idf = [0.069, 0, 0, 0, 0, 0, 0, 0, 0, 0.187, 0.187, 0.187, 0.187]   \n",
    "sentence3_vector_BOW =    [1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1]\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform([sentence1, sentence2, sentence3])\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to convert text data into numerical data using Bag of words and need to save that count vetorizer object in pickle file for test data conversion\n",
    "def text_to_bow(corpus):\n",
    "    cv_object = CountVectorizer()\n",
    "    X_bow = cv_object.fit_transform(corpus)\n",
    "    # we need to save this cv_object in pickle file for test data conversion\n",
    "    # saving the count vectorizer object in pickle file\n",
    "    with open('count_vectorizer.pkl', 'wb') as f:\n",
    "        pickle.dump(cv_object, f)\n",
    "    return X_bow, cv_object\n",
    "\n",
    "\n",
    "X_bow , cv_object = text_to_bow(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bow_array = X_bow.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41752, 25399)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        great flavor lotsa heat use cayenn almost ever...\n",
       "1        skeptic order troubl cup explod find howev ful...\n",
       "2        love faucet husband instal one old hous curren...\n",
       "3        dog come outsid train look cupboard wait treat...\n",
       "4        everi month give three dog two aussi golden fl...\n",
       "                               ...                        \n",
       "41747    big quinoa fan decid give kaniwa tri similar m...\n",
       "41748    good earth restaur tea addict continu onlin pu...\n",
       "41749    avid tea drinker drink lot green everi day gre...\n",
       "41750    one smooth rick dark chocol treat gevalia truf...\n",
       "41751    pro gevalia say dark chocol mean con sinc oz b...\n",
       "Name: Cleaned_Text, Length: 41752, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model using the training sets\n",
    "model.fit(X_bow,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for test dataset\n",
    "y_train_pred = model.predict(X_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.888196972600115\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[ 6643  2995]\n",
      " [ 1673 30441]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_train, y_train_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "# we need to convert the X_test data into numerical data using the count vectorizer object which"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on train data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.69      0.74      9638\n",
      "           1       0.91      0.95      0.93     32114\n",
      "\n",
      "    accuracy                           0.89     41752\n",
      "   macro avg       0.85      0.82      0.83     41752\n",
      "weighted avg       0.88      0.89      0.89     41752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report on train data:\\n\", classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to convert the text data into numerical data by using saved count vectorizer object\n",
    "# loading the count vectorizer object from pickle file\n",
    "#Create a function to convert text data into numerical data using Bag of words for test data conversion\n",
    "def text_to_bow_test(corpus):\n",
    "    with open('count_vectorizer.pkl', 'rb') as f:\n",
    "        loaded_cv_object = pickle.load(f)\n",
    "    X_bow = loaded_cv_object.transform(corpus)\n",
    "    return X_bow\n",
    "\n",
    "X_test_bow = text_to_bow_test(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on test data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.52      0.59      1812\n",
      "           1       0.90      0.95      0.93      8627\n",
      "\n",
      "    accuracy                           0.88     10439\n",
      "   macro avg       0.79      0.74      0.76     10439\n",
      "weighted avg       0.87      0.88      0.87     10439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classiffication report\n",
    "print(\"Classification Report on test data:\\n\", classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DecisionTreeClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we need to try with decision tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on train data using Decision Tree Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9638\n",
      "           1       1.00      1.00      1.00     32114\n",
      "\n",
      "    accuracy                           1.00     41752\n",
      "   macro avg       1.00      1.00      1.00     41752\n",
      "weighted avg       1.00      1.00      1.00     41752\n",
      "\n",
      "Classification Report on test data using Decision Tree Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.44      0.44      1812\n",
      "           1       0.88      0.88      0.88      8627\n",
      "\n",
      "    accuracy                           0.80     10439\n",
      "   macro avg       0.66      0.66      0.66     10439\n",
      "weighted avg       0.80      0.80      0.80     10439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_dt = dt_model.predict(X_bow)\n",
    "y_test_pred_dt = dt_model.predict(X_test_bow)\n",
    "print(\"Classification Report on train data using Decision Tree Classifier:\\n\", classification_report(y_train,y_train_pred_dt))\n",
    "print(\"Classification Report on test data using Decision Tree Classifier:\\n\", classification_report(y_test,y_test_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on train data using Random Forest Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9638\n",
      "           1       1.00      1.00      1.00     32114\n",
      "\n",
      "    accuracy                           1.00     41752\n",
      "   macro avg       1.00      1.00      1.00     41752\n",
      "weighted avg       1.00      1.00      1.00     41752\n",
      "\n",
      "Classification Report on test data using Random Forest Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.21      0.34      1812\n",
      "           1       0.86      0.99      0.92      8627\n",
      "\n",
      "    accuracy                           0.86     10439\n",
      "   macro avg       0.87      0.60      0.63     10439\n",
      "weighted avg       0.86      0.86      0.82     10439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now we will try on Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_bow, y_train)\n",
    "y_train_pred_rf = rf_model.predict(X_bow)\n",
    "y_test_pred_rf = rf_model.predict(X_test_bow)   \n",
    "print(\"Classification Report on train data using Random Forest Classifier:\\n\", classification_report(y_train,y_train_pred_rf))\n",
    "print(\"Classification Report on test data using Random Forest Classifier:\\n\", classification_report(y_test,y_test_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class label o having 10k rows \n",
    "and class label1 having 30k rows\n",
    "The data set is imbalanced data set\n",
    "# we need to do balancing the data set using SMOTE or ADASYN or RandomOverSampler or RandomUnderSampler\n",
    "\n",
    "Over sampling \n",
    "In our data\n",
    "label1 --1000 rows\n",
    "label0 ---100 rows    * 10  --- 1000 rows it will become\n",
    "\n",
    "SMoke technique:\n",
    "SMOKe is synthetic minority oversampling technique\n",
    "lablel1 --1000rows\n",
    "label0 --100rows  --- we are adding 900 rows--- no data loss    \n",
    "\n",
    "\n",
    "\n",
    "Undersampling Tecnique:\n",
    "lablel1 --100rows  --- we are dropping 900 rows--- data loss is there\n",
    "label0 --100rows\n",
    "\n",
    "\n",
    "RandomOverSampler:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE (Synthetic Minority Oversampling Technique) Explanation\n",
    "SMOTE is a popular technique for handling imbalanced datasets, especially in classification problems. When one class (minority) has significantly fewer samples than another (majority), models can become biased toward the majority class. SMOTE helps to balance the dataset by generating synthetic samples for the minority class.\n",
    "\n",
    "**How SMOTE Works:**\n",
    "1. For each sample in the minority class, SMOTE selects one or more of its nearest neighbors (typically using Euclidean distance).\n",
    "2. It then creates new synthetic samples by interpolating between the original sample and its neighbors. This is done by taking the difference between the feature vector of the sample and its neighbor, multiplying it by a random number between 0 and 1, and adding it to the original sample.\n",
    "3. The result is a new, plausible sample that lies along the line segment between the two points in feature space.\n",
    "\n",
    "**Benefits:**\n",
    "- Reduces bias toward the majority class.\n",
    "- Helps improve model performance on the minority class.\n",
    "- No information loss, as opposed to undersampling.\n",
    "\n",
    "**Limitations:**\n",
    "- Synthetic samples may introduce noise if the minority class is not well represented.\n",
    "- Works best with continuous features; may not be ideal for categorical data.\n",
    "\n",
    "**Example:**\n",
    "Suppose you have 100 samples of class 0 and 10 samples of class 1. SMOTE can generate 90 synthetic samples for class 1, resulting in a balanced dataset with 100 samples for each class.\n",
    "\n",
    "**Implementation:**\n",
    "SMOTE is available in Python via the `imblearn` library:\n",
    "```python\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on train data using XGBoost Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.65      0.76      9638\n",
      "           1       0.90      0.98      0.94     32114\n",
      "\n",
      "    accuracy                           0.90     41752\n",
      "   macro avg       0.90      0.82      0.85     41752\n",
      "weighted avg       0.90      0.90      0.90     41752\n",
      "\n",
      "Classification Report on test data using XGBoost Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.45      0.56      1812\n",
      "           1       0.89      0.96      0.93      8627\n",
      "\n",
      "    accuracy                           0.88     10439\n",
      "   macro avg       0.81      0.71      0.74     10439\n",
      "weighted avg       0.87      0.88      0.86     10439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now we will try with Xgboost classifier\n",
    "import xgboost as xgb\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(X_bow, y_train)\n",
    "y_train_pred_xgb = xgb_model.predict(X_bow)\n",
    "y_test_pred_xgb = xgb_model.predict(X_test_bow)\n",
    "print(\"Classification Report on train data using XGBoost Classifier:\\n\", classification_report(y_train,y_train_pred_xgb))\n",
    "print(\"Classification Report on test data using XGBoost Classifier:\\n\", classification_report(y_test,y_test_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an explanation of each parameter in the param_grid for Random Forest hyperparameter tuning:\n",
    "\n",
    "n_estimators: Number of trees in the forest. More trees can improve performance but increase computation time.\n",
    "\n",
    "max_depth: Maximum depth of each tree. Controls how deep the tree can grow. None means nodes are expanded until all leaves are pure.\n",
    "\n",
    "min_samples_split: Minimum number of samples required to split an internal node. Higher values prevent the model from learning overly specific patterns (overfitting).\n",
    "\n",
    "min_samples_leaf: Minimum number of samples required to be at a leaf node. Useful for smoothing the model, especially for regression.\n",
    "\n",
    "max_features: Number of features to consider when looking for the best split. 'auto' (all features), 'sqrt' (square root of total features), 'log2' (log base 2 of total features).\n",
    "\n",
    "bootstrap: Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.\n",
    "\n",
    "class_weight: Weights associated with classes. 'balanced' adjusts weights inversely proportional to class frequencies, useful for imbalanced datasets.\n",
    "\n",
    "criterion: Function to measure the quality of a split. 'gini' for Gini impurity, 'entropy' for information gain.\n",
    "\n",
    "These parameters help control the complexity, randomness, and bias/variance trade-off of the Random Forest model. Tuning them can improve accuracy and generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classifier -- is the combination of multiple decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1944 candidates, totalling 5832 fits\n"
     ]
    }
   ],
   "source": [
    "# We need to do Hyperparameter tuning for all the models to improve the accuracy and other metrics\n",
    "# We need to do cross validation for all the models to improve the accuracy and other metrics\n",
    "# first we will do hyperparameter tuning for Random Forest Classifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'bootstrap': [True, False],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "#comb1 -- 50, None, 2, 1, auto, True,None, gini\n",
    "#comb2 -- 50, None, 2, 1, auto, True,None, entropy\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_bow, y_train)\n",
    "\n",
    "'''\n",
    "train data -- 30,000 rows\n",
    "cv = 3\n",
    "30,000/3 = 10,000 rows in each fold\n",
    "2fold for training and 1 fold for validation\n",
    "    \n",
    "for example if we take CV=5\n",
    "30,000/5 = 6,000 rows in each fold\n",
    "4 folds for training and 1 fold for validation\n",
    "\n",
    "Train data, Validation data, test data\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomSearchCv -- it will take random combinations of hyperparameters   -- if i give 300 value -- out of 1944 it will take only 300 combinations randomly selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grid_search' is not defined"
     ]
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on train data using Tuned Random Forest Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.03      0.05      9638\n",
      "           1       0.77      1.00      0.87     32114\n",
      "\n",
      "    accuracy                           0.78     41752\n",
      "   macro avg       0.89      0.51      0.46     41752\n",
      "weighted avg       0.83      0.78      0.68     41752\n",
      "\n",
      "Classification Report on test data using Tuned Random Forest Classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00      1812\n",
      "           1       0.83      1.00      0.91      8627\n",
      "\n",
      "    accuracy                           0.83     10439\n",
      "   macro avg       0.91      0.50      0.45     10439\n",
      "weighted avg       0.86      0.83      0.75     10439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model_tuned = RandomForestClassifier(n_estimators=200, max_depth=20, min_samples_split=5, min_samples_leaf=1, max_features='sqrt', bootstrap=True, class_weight=None, criterion='gini')\n",
    "rf_model_tuned.fit(X_bow, y_train)\n",
    "y_train_pred_rf_tuned = rf_model_tuned.predict(X_bow)\n",
    "y_test_pred_rf_tuned = rf_model_tuned.predict(X_test_bow)\n",
    "print(\"Classification Report on train data using Tuned Random Forest Classifier:\\n\", classification_report(y_train,y_train_pred_rf_tuned))\n",
    "print(\"Classification Report on test data using Tuned Random Forest Classifier:\\n\", classification_report(y_test,y_test_pred_rf_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With above code still if we are not getting accuracy let us apply Over sampling on the training dataset\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64228, 25399)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        0\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "64223    0\n",
       "64224    0\n",
       "64225    0\n",
       "64226    0\n",
       "64227    0\n",
       "Name: Class_Labels, Length: 64228, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on train data using Tuned Random Forest Classifier after OverSampling:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.83      0.78      9638\n",
      "           1       0.95      0.91      0.93     32114\n",
      "\n",
      "    accuracy                           0.89     41752\n",
      "   macro avg       0.85      0.87      0.86     41752\n",
      "weighted avg       0.90      0.89      0.90     41752\n",
      "\n",
      "Classification Report on test data using Tuned Random Forest Classifier after OverSampling:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.66      0.61      1812\n",
      "           1       0.93      0.90      0.91      8627\n",
      "\n",
      "    accuracy                           0.86     10439\n",
      "   macro avg       0.75      0.78      0.76     10439\n",
      "weighted avg       0.87      0.86      0.86     10439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build the random forest model on the resampled data\n",
    "rf_model_tuned = RandomForestClassifier(n_estimators=200, max_depth=20, min_samples_split=5, min_samples_leaf=1, max_features='sqrt', bootstrap=True, class_weight=None, criterion='gini')\n",
    "rf_model_tuned.fit(X_resampled, y_resampled)\n",
    "y_train_pred_rf_tuned = rf_model_tuned.predict(X_bow)\n",
    "y_test_pred_rf_tuned = rf_model_tuned.predict(X_test_bow)\n",
    "print(\"Classification Report on train data using Tuned Random Forest Classifier after OverSampling:\\n\", classification_report(y_train,y_train_pred_rf_tuned))\n",
    "print(\"Classification Report on test data using Tuned Random Forest Classifier after OverSampling:\\n\", classification_report(y_test,y_test_pred_rf_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the rf_model_tuned in pickle file\n",
    "with open('sentiment_model_bow.pkl', 'wb') as f: \n",
    "    pickle.dump(rf_model_tuned, f)\n",
    "\n",
    "#save the bow vectorizer object in pickle file\n",
    "with open('vectorizer_bow.pkl', 'wb') as f: \n",
    "    pickle.dump(cv_object, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
